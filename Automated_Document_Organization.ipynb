{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JQimxdil5C6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "#______________________________________________\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "#_______________________________________________\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "eQNqknMZ4_wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8SgtRj4G0iF"
      },
      "outputs": [],
      "source": [
        "\n",
        "base_dir = '/content/drive/MyDrive'\n",
        "train_dir = os.path.join(base_dir, 'Dataset')\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To train Model\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/img_classification_model2.h5')\n"
      ],
      "metadata": {
        "id": "UVXG0owgImie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Directory= r'/content/drive/MyDrive/Test'\n",
        "data=[]\n",
        "for img_item in os.listdir(Directory):\n",
        "  img_item=os.path.join(Directory,img_item)\n",
        "  data.append(img_item)\n",
        "\n",
        "RefImage= r'/content/drive/MyDrive/Check'\n",
        "Ref=[]\n",
        "for img_item in os.listdir(RefImage):\n",
        "  img_item=os.path.join(RefImage,img_item)\n",
        "  Ref.append(img_item)\n"
      ],
      "metadata": {
        "id": "-QJM44-oQttt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "saved_model = tf.keras.models.load_model('/content/drive/MyDrive/img_classification_model2.h5')\n",
        "index=0\n",
        "for item in data:\n",
        "  image = cv2.imread(item)\n",
        "  img=image\n",
        "\n",
        "  image= cv2.resize(image, (224, 224))\n",
        "\n",
        "  # Convert the image to array and normalize\n",
        "  image_array = img_to_array(image) / 255.0\n",
        "  image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = saved_model.predict(image_array)\n",
        "  label_index = np.argmax(predictions)\n",
        "  class_labels = train_generator.class_indices\n",
        "\n",
        "  # Get the predicted label\n",
        "  predicted_label = [k for k, v in class_labels.items() if v == label_index][0]\n",
        "  print('Predicted label:', predicted_label)\n",
        "\n",
        "  if predicted_label==\"advance\":\n",
        "    ref = cv2.imread(Ref[0])\n",
        "  elif predicted_label==\"expense\":\n",
        "    ref = cv2.imread(Ref[1])\n",
        "  elif predicted_label==\"internet\":\n",
        "    ref = cv2.imread(Ref[2])\n",
        "  elif predicted_label==\"bill\":\n",
        "    ref = cv2.imread(Ref[3])\n",
        "\n",
        "  print(\"___________________________________\")\n",
        "  # Detect keypoints and extract descriptors using SIFT\n",
        "  sift = cv2.xfeatures2d.SIFT_create()\n",
        "  kp_img, des_img = sift.detectAndCompute(img, None)\n",
        "  kp_ref, des_ref = sift.detectAndCompute(ref, None)\n",
        "\n",
        "  # Match keypoints between the images\n",
        "  bf = cv2.BFMatcher()\n",
        "  matches = bf.knnMatch(des_img, des_ref, k=2)\n",
        "\n",
        "  # Apply ratio test to filter out bad matches\n",
        "  good_matches = []\n",
        "  for m, n in matches:\n",
        "      if m.distance < 0.75 * n.distance:\n",
        "          good_matches.append(m)\n",
        "\n",
        "  # Draw the matched keypoints\n",
        "  img_match = cv2.drawMatches(img, kp_img, ref, kp_ref, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "  # Extract the matched keypoints' coordinates\n",
        "  src_pts = np.float32([kp_img[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "  dst_pts = np.float32([kp_ref[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "  # Calculate the homography matrix\n",
        "  H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "  # Apply the homography transformation to the image\n",
        "  warped_img = cv2.warpPerspective(img, H, (ref.shape[1], ref.shape[0]))\n",
        "\n",
        "  # display(warped_img)\n",
        "  # Display the original image, reference image, and warped image\n",
        "  index+=1\n",
        "  resized_img = cv2.resize(warped_img, (300, 200))\n",
        "  cv2_imshow(resized_img)\n",
        "  if predicted_label==\"advance\":\n",
        "    folder_path = '/content/drive/MyDrive/Sort/advance/'\n",
        "  elif predicted_label==\"expense\":\n",
        "    folder_path = '/content/drive/MyDrive/Sort/expense/'\n",
        "  elif predicted_label==\"internet\":\n",
        "    folder_path = '/content/drive/MyDrive/Sort/internet/'\n",
        "  elif predicted_label==\"bill\":\n",
        "    folder_path = '/content/drive/MyDrive/Sort/bill/'\n",
        "\n",
        "  cv2.imwrite(folder_path + f'{index}.png', warped_img)\n",
        "\n"
      ],
      "metadata": {
        "id": "x-BT8SugMmMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}